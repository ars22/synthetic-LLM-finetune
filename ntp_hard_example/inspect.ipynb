{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/asetlur/anaconda3/envs/syth-llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data import get_dataset\n",
    "from utils.training_utils import get_lr, get_run_name, AverageMeter\n",
    "from torch.utils.data import DataLoader\n",
    "from evaluate_model import evaluate, evaluate_forced\n",
    "from models import get_model\n",
    "from tokenizing import get_tokenizer\n",
    "import wandb\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--wandb_entity'], dest='wandb_entity', nargs=None, const=None, default=5000, type=<class 'str'>, choices=None, required=False, help='Wandb username', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Next-token failures\")\n",
    "# Data\n",
    "parser.add_argument(\n",
    "    \"--model\", default='gpt2', type=str, help=\"Type of model\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "    \"--dataset\", default='graph', type=str, help=\"Choice of dataset\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "    \"--n_train\", default=200000, type=int, help=\"Number of training samples\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "    \"--n_test\", default=5000, type=int, help=\"Number of test samples\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "    \"--num_nodes\", default=50, type=int, help=\"Number of node values in graph\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "    \"--deg\", default=2, type=int, help=\"Degree of starting node\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "    \"--path_len\", default=5, type=int, help=\"Path length in star graph\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--mate_in\", default=2, type=int, help=\"For chess, number of moves to checkmate\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--unrolled\", action=argparse.BooleanOptionalAction, default=True, help=\"For chess, unrolled board state\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--batch_size\", type=int, default=256, help=\"Batch size\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--lr\", type=float, default=5e-4, help=\"Learning rate\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--weight_decay\", type=float, default=1e-2, help=\"Strength of weight decay\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--epochs\", type=int, default=100, help=\"Number of epochs\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--save_every\", type=int, default=5000, help=\"Interval (in steps) at which to save model\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--teacherless\", action=argparse.BooleanOptionalAction, default=False, help=\"Standard or teacherless training\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--reverse\", action=argparse.BooleanOptionalAction, default=False, help=\"Standard format or reverse targets\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--cot\", action=argparse.BooleanOptionalAction, default=False, help=\"Standard format or cot targets\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--eval_train\", action=argparse.BooleanOptionalAction, default=False, help=\"Eval for training set\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--eval_every\", type=int, default=400, help=\"Interval (in steps) to evaluate the model on test\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--use_wandb\", action=argparse.BooleanOptionalAction, default=False, help=\"Whether to use wandb\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"--wandb_entity\", type=str, default=5000, help=\"Wandb username\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal sequence lengths!\n",
      "Equal sequence lengths!\n"
     ]
    }
   ],
   "source": [
    "args.cot = True\n",
    "device = 'cpu'\n",
    "tokenizer = get_tokenizer(args)\n",
    "train_data, test_data = get_dataset(args, tokenizer, device)\n",
    "# train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=args.batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49,13|23,28|46,35|32,42|35,32|42,22|13,23|46,49/46,22=22,42,32,35,46:46,35,32,42,22\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/datasets/graphs/deg_2_path_5_nodes_50_train_200000.txt'\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    prefix = line.strip().split('=')[0] + '='\n",
    "    target = line.strip().split('=')[1]\n",
    "    reverse = False\n",
    "    cot = True\n",
    "    if reverse:\n",
    "        target = ','.join(target.split(',')[::-1])\n",
    "    if cot:\n",
    "        if reverse:\n",
    "            raise ValueError(\"Cannot be cot and reverse at the same time.\")\n",
    "        rev_path = target.split(',')[::-1]\n",
    "        path_str = ''\n",
    "        for node in rev_path:\n",
    "            path_str += str(node) + ','\n",
    "        path_str = path_str[:-1] + ':' + target\n",
    "        target = path_str\n",
    "    print(prefix+target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('49,13|23,28|46,35|32,42|35,32|42,22|13,23|46,49/46,22=',\n",
       " '22,42,32,35,46$46,35,32,42,22')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('49,13|23,28|46,35|32,42|35,32|42,22|13,23|46,49/46,22=', '46,35,32,42,22')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syth-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
