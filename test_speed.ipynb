{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asetlur/anaconda3/envs/syth-llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "from typing import Dict, List, Optional, Iterator, Callable, Union, Tuple\n",
    "import datasets\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import re\n",
    "from rouge_score import rouge_scorer\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy_and_tokenizer(model_name: str):\n",
    "\n",
    "    # fetch model and tokenizer\n",
    "    if model_name == 'llama2-7b':\n",
    "        model_path = 'NousResearch/Llama-2-7b-hf'\n",
    "        chat_template = \"<s> {}\"\n",
    "    elif model_name == 'llama2-7b-chat':\n",
    "        model_path = 'NousResearch/Llama-2-7b-chat-hf'\n",
    "        chat_template = \"<s>[INST] {} End your answer as, 'Hence the answer is: '. [/INST]\"\n",
    "    elif model_name == 'mistral-7b':\n",
    "        model_path = 'mistralai/Mistral-7B-v0.1'\n",
    "        chat_template = \"<s> {}\"\n",
    "    elif model_name == 'mistral-7b-chat':\n",
    "        model_path = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
    "        chat_template = \"<s>[INST] {} End your answer as, 'Hence the answer is: '. [/INST]\"\n",
    "    elif model_name == 'gemma-7b':\n",
    "        model_path = 'google/gemma-7b'\n",
    "        chat_template = \"{}\"\n",
    "    elif model_name == 'gemma-7b-chat':\n",
    "        model_path = 'google/gemma-7b-it'\n",
    "        chat_template = \"<bos><start_of_turn>user\\n {} <end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "\n",
    "    policy = transformers.AutoModelForCausalLM.from_pretrained(model_path, device_map='balanced', torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\")\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_path, padding_side='left')\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    return policy, tokenizer, chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in llama2-7b: 6738415616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in llama2-7b-chat: 6738415616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in gemma-7b: 8537680896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in gemma-7b-chat: 8537680896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in mistral-7b: 7241732096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in mistral-7b-chat: 7241732096\n"
     ]
    }
   ],
   "source": [
    "model_name = 'llama2-7b'\n",
    "policy, tokenizer, chat_template = get_policy_and_tokenizer(model_name)\n",
    "num_params = policy.num_parameters()\n",
    "print(f\"Number of parameters in {model_name}: {num_params}\")\n",
    "\n",
    "model_name = 'llama2-7b-chat'\n",
    "policy, tokenizer, chat_template = get_policy_and_tokenizer(model_name)\n",
    "num_params = policy.num_parameters()\n",
    "print(f\"Number of parameters in {model_name}: {num_params}\")\n",
    "\n",
    "model_name = 'gemma-7b'\n",
    "policy, tokenizer, chat_template = get_policy_and_tokenizer(model_name)\n",
    "num_params = policy.num_parameters()\n",
    "print(f\"Number of parameters in {model_name}: {num_params}\")\n",
    "\n",
    "model_name = 'gemma-7b-chat'\n",
    "policy, tokenizer, chat_template = get_policy_and_tokenizer(model_name)\n",
    "num_params = policy.num_parameters()\n",
    "print(f\"Number of parameters in {model_name}: {num_params}\")\n",
    "\n",
    "model_name = 'mistral-7b'\n",
    "policy, tokenizer, chat_template = get_policy_and_tokenizer(model_name)\n",
    "num_params = policy.num_parameters()\n",
    "print(f\"Number of parameters in {model_name}: {num_params}\")\n",
    "\n",
    "model_name = 'mistral-7b-chat'\n",
    "policy, tokenizer, chat_template = get_policy_and_tokenizer(model_name)\n",
    "num_params = policy.num_parameters()\n",
    "print(f\"Number of parameters in {model_name}: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Harry Potter is a famous wizard.\",\n",
    "    \"Hermione Granger is known for her intelligence.\",\n",
    "    \"Ron Weasley is Harry's best friend.\",\n",
    "    \"The Hogwarts School of Witchcraft and Wizardry is where Harry studied.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'mistral-7b-chat'\n",
    "policy, tokenizer, chat_template = get_policy_and_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[INST] Harry Potter is a famous wizard. End your answer as, 'Hence the answer is: '. [/INST] Harry Potter is a famous wizard. He is known for his bravery, intelligence, and leadership skills. He is also known for his friendship with his best friends, Hermione Granger and Ron Weasley. Harry has faced many challenges throughout his life, including battling against the dark lord Voldemort and saving the world from evil. Despite these challenges, he never gave up and always did what was right. Hence the answer is: Harry Potter is a legendary wizard known for his bravery, intelligence, and leadership skills.\",\n",
       " \"[INST] Hermione Granger is known for her intelligence. End your answer as, 'Hence the answer is: '. [/INST] Hermione Granger is known for her intelligence. She consistently outperforms her peers in academic subjects and uses her knowledge to solve complex problems. Her dedication to learning and her ability to think critically have helped her overcome numerous challenges throughout her life. Hence the answer is: Hermione Granger's intelligence is a defining characteristic of her personality.\",\n",
       " \"[INST] Ron Weasley is Harry's best friend. End your answer as, 'Hence the answer is: '. [/INST] Ron Weasley is Harry's best friend. Hence the answer is: Ron Weasley.\",\n",
       " \"[INST] The Hogwarts School of Witchcraft and Wizardry is where Harry studied. End your answer as, 'Hence the answer is: '. [/INST] The Hogwarts School of Witchcraft and Wizardry is where Harry studied. Hence the answer is: Hogwarts.\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "encoded = tokenizer.batch_encode_plus([chat_template.format(x) for x in sentences], padding=True, return_tensors='pt', max_length=128, truncation=True)\n",
    "encoded = {k: v.to(policy.device) for k, v in encoded.items()}\n",
    "generation = policy.generate(**encoded, max_new_tokens=128, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.batch_decode(generation, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[INST] Harry Potter is a famous wizard. End your answer as, 'Hence the answer is: '. [/INST] Harry Potter is a famous wizard. He is known for his bravery, intelligence, and leadership skills. He is also known for his friendship with his best friends, Hermione Granger and Ron Weasley. Harry has faced many challenges throughout his life, including the death of his parents, the rise of Voldemort, and the final battle against the Dark Lord. Despite these challenges, Harry has always remained true to his values and has become an inspiration to millions of people around the world. Hence the answer is: Harry Potter is a famous wizard known for his bravery, intelligence, leadership, friendship,\",\n",
       " \"[INST] Hermione Granger is known for her intelligence. End your answer as, 'Hence the answer is: '. [/INST] Hermione Granger is known for her intelligence. She consistently outperforms her peers in academic subjects and uses her knowledge to solve complex problems. Her dedication to learning and her ability to think critically have helped her overcome numerous challenges throughout her life. Hence the answer is: Hermione Granger's intelligence is a defining characteristic of her personality.\",\n",
       " \"[INST] Ron Weasley is Harry's best friend. End your answer as, 'Hence the answer is: '. [/INST] Ron Weasley is Harry's best friend. Hence the answer is: Ron Weasley.\",\n",
       " \"[INST] The Hogwarts School of Witchcraft and Wizardry is where Harry studied. End your answer as, 'Hence the answer is: '. [/INST] The Hogwarts School of Witchcraft and Wizardry is where Harry studied. Hence the answer is: Hogwarts.\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.half()\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "encoded = tokenizer.batch_encode_plus([chat_template.format(x) for x in sentences], padding=True, return_tensors='pt', max_length=128, truncation=True)\n",
    "encoded = {k: v.to(policy.device) for k, v in encoded.items()}\n",
    "generation = policy.generate(**encoded, max_new_tokens=128, num_return_sequences=1, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.batch_decode(generation, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syth-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
